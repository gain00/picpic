# hadoop 가상분산모드 설치
1대의 시스템이 하둡 클러스터로 작동하도록 설치하는 방식

클러스터cluster : 서버 그룹
여러 대의 컴퓨터들이 하나의 시스템처럼 작동하는 
컴퓨터들의 집합

하둡클러스터 구성
   HDFS (데이터저장) : NameNode (2nd NameNode), DataNode
   YRAN (리소스관리) : ResourceManager, NodeManager


0. 관리자 계정 전환
sudo su
암호입력

date -s '2023-09-01 09:55'   (시간설정)


1. 가상분산 설치를 위해 방화벽 설정 (방화벽 해제)
systemctl  stop  firewalld    (중지)
systemctl  disable  firewalld    (자동실행 중지)


2. 가상분산 설치를 위해 공개키 설정
hadoop01 <-> hadoop02 <-> hadoop03 <-> hadoop04

NameNode <-> DataNode
         <-> ResourceManager <-> NodeManager

각 시스템에 ssh접속시 아이디/비밀번호 입력을 요구받음
이러한 과정을 생략하고 싶다면 hadoop01에서 로그인할 계정에
대한 공개키를 생성하고 각 시스템에 복사해두면 됨

su   hadoop   (hadoop 계정으로 전환)

cd   (hadoop 홈디렉토리로 변경)

hadoop 계정에 대한 공개키 생성
# t : 공개키 암호화 유형, RSA로 설정
# P : 보조암호 설정 여부 지정, 여기서는 없음으로 설정
ssh-keygen  -t   rsa   -P   ""
엔터      (공개키 저장위치는 기본위치)


생성한 공개키를 centos7 서버의 특정위치에 복사해 둠
# ssh-copy-id -i 복사위치 사용자명@서버명
# 따라서, 특정사용자명으로 서버에 접속시 암호입력은 
# 복사해둔 공개키파일로 대신한다는 의미
ssh-copy-id  -i   ~/.ssh/id_rsa.pub  \
hadoop@hadoop
yes 입력
hadoop계정의 암호입력


3. hadoop 가상분산모드를 위한 환경설정
core-site.xml   : hadoop 전반에 대한 설정
hdfs-site.xml   : hdfs 관련 설정
yarn-site.xml   : yarn 관련 설정
mapred-site.xml : 맵리듀스 관련 설정

cd $HAD[탭키]
cd etc/hadoop   (hadoop 환경설정 디렉토리로 이동)

1) vi  core-site.xml
<property>
    <name>fs.defaultFS</name>
    <value>hdfs://localhost:9000</value>
</property>
<property>
    <name>hadoop.tmp.dir</name>
    <value>/usr/share/hadoop/tmp</value>
</property>

2) vi hdfs-site.xml
<property>
  <name>dfs.replication</name>
  <value>1</value>
</property>
<property>
  <name>dfs.namenode.name.dir</name>
  <value>/usr/share/hadoop/data/dfs/namenode</value>
</property>
<property>
  <name>dfs.datanode.data.dir</name>
  <value>/usr/share/hadoop/data/dfs/datanode</value>
</property>


3) vi yarn-site.xml
<property>
        <name>yarn.resourcemanager.hostname</name>
        <value>localhost</value>
</property>
<property>
        <name>yarn.nodemanager.aux-services</name>
        <value>mapreduce_shuffle</value>
</property>


4) vi mapred-site.xml
<property>
       <name>mapreduce.framework.name</name>
       <value>yarn</value>
</property>

# hadoop 3.x에서는 다음 내용을 vi mapred-site.xml에 추가
 <property>
   <name>yarn.app.mapreduce.am.env</name>
   <value>HADOOP_MAPRED_HOME=/usr/share/hadoop</value>
 </property>
 <property>
   <name>mapreduce.map.env</name>
   <value>HADOOP_MAPRED_HOME=/usr/share/hadoop</value>
 </property>
 <property>
   <name>mapreduce.reduce.env</name>
   <value>HADOOP_MAPRED_HOME=/usr/share/hadoop</value>
  </property>


4. 가상분산모드관련 디렉토리 생성
cd $HADOOP_HOME

mkdir tmp
mkdir -p data/dfs/namenode
mkdir -p data/dfs/datanode
chmod 755 data/dfs/namenode
chmod 755 data/dfs/datanode

ls  data/dfs   (datanode, namenode 확인)


5. 가상분산모드 실행준비1 : namenode 포맷
hdfs  namenode  -format

(namenode has been successfully formatted.) 확인


6. 가상분산모드 실행준비2 : datanode 실행
start-dfs.sh
yes입력
yes입력

starting namenode
starting datanode
secondary namenodes 메세지들 확인

7. 가상분산모드 실행준비3 : ResourceManager/NodeManager 실행
start-yarn.sh

starting resourcemanager
starting nodemanager    메세지들 확인

8. 가상분산모드 실행준비4 : HDFS, YARN 실행여부 확인
jps

5826 NameNode
5954 DataNode
6311 ResourceManager
6120 SecondaryNameNode
6413 NodeManager    메세지 확인 (PID 달라도 상관없음)


9. 가상분산모드 실행준비5 :  datanode 실행상황 확인
hdfs  dfsadmin  -report

Configured Capacity: 18238930944 (16.99 GB) 확인


10. 가상분산모드 실행준비6 : ResourceManager 실행여부
yarn  node  -list

RUNNING      ?????:8042      확인


11.  가상분산모드 실행확인1 : HDFS 웹 UI
브라우져 실행 후 "가상머신IP:50070" 입력  (hadoop 2.x)

브라우져 실행 후 "가상머신IP:9870" 입력  (hadoop 3.x)


13. 사용자 HDFS 작업영역 생성
hadoop 사용자가 HDFS 저장소에 파일을 업로드할 수 있도록
저장공간을 생성해야 함
즉, hadoop을 이용해서 데이터 처리 작업을 수행하려면
먼저 관련 데이터를 HDFS 저장영역에 업로드해둬야 함

hadoop  fs   -mkdir  -p   /user/hadoop

hadoop fs  -chown  hadoop:hadoop  /user/hadoop

hadoop fs  -mkdir  /tmp

hadoop fs  -chmod   777   /tmp

hadoop  fs  -ls  /   (user, tmp 디렉토리 확인)

hadoop  fs  -ls  /user


14. 가상분산모드 실행 테스트1
cd $HAD[탭키]

hadoop jar \
share/hadoop/mapreduce/hadoop-mapreduce-examples-3.3.4.jar \
pi 16 1000


주의사항!
만일, 시스템을 종료/재시작해야 할 경우
=> HDFS와 YARN 을 먼저 중지해야 함
=> 중지순서는 시작순서의 역순으로 진행

start-dfs.sh     (시작순서)
start-yarn.sh

stop-yarn.sh     (종료순서)
stop-dfs.sh

poweroff

----------------------------

15. 가상분산모드 실행 테스트2 - 단어검색

source /etc/profile

cd $HAD[탭키]

start-dfs.sh
start-yarn.sh

jps   (6개 프로세스 실행 확인)